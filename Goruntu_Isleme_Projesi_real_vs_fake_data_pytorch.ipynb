{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQShxsQyTtvP",
        "outputId": "33ab6cdd-18b3-462a-8085-496caf9f5b9e"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive,files\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Klasör yolunu girin\n",
        "workspace_path = \"C:/Users/celal/Documents/Github/goruntu-isleme-projesi/\"\n",
        "\n",
        "# Klasörü workspace olarak ayarlayın\n",
        "os.chdir(workspace_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "1ihAQweaU6pV",
        "outputId": "a48394af-80bd-4f00-d01f-ce84c3b46f5f"
      },
      "outputs": [],
      "source": [
        "# Kaggle API anahtarını Colab'a yükleme\n",
        "uploaded = files.upload()\n",
        "\n",
        "# API anahtarını yerel dizine taşıma\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Veri setlerini indirme\n",
        "!kaggle datasets download -d undersc0re/fake-vs-real-face-classification\n",
        "\n",
        "# Zip dosyalarının taşınacağı dizinleri tanımla\n",
        "fake_vs_real_zip = workspace_path + 'fake-vs-real-face-classification.zip'\n",
        "\n",
        "# Çıkarılacak dizinleri tanımla\n",
        "fake_vs_real_folder = workspace_path + 'real-vs-fake'\n",
        "\n",
        "# Gerekli klasörleri oluştur\n",
        "os.makedirs(fake_vs_real_folder, exist_ok=True)\n",
        "\n",
        "# Zip dosyalarını çıkar\n",
        "!unzip -q $fake_vs_real_zip -d $fake_vs_real_folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZPfqvPaWdJu"
      },
      "outputs": [],
      "source": [
        "train_dir = workspace_path+ 'real-vs-fake/train/'\n",
        "valid_dir = workspace_path+'real-vs-fake/Validation/'\n",
        "test_dir = workspace_path+'real-vs-fake/test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9VoJbIzXXuG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2S1pq2uWspv"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([transforms.Resize((512,512)),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomAutocontrast(0.3),\n",
        "                                       transforms.RandomAffine(5),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "valid_transforms = transforms.Compose([transforms.Resize((512,512)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize((512,512)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhPh5osuXasB"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True)\n",
        "validloader = torch.utils.data.DataLoader(valid_data, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww2icQP6XdtF",
        "outputId": "421d4ff3-0b40-4322-ee41-59c585ded620"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class_names = os.listdir(train_dir)\n",
        "train_image_count = {}\n",
        "valid_image_count = {}\n",
        "test_image_count = {}\n",
        "\n",
        "for i in class_names:\n",
        "    train_image_count[i] = len(os.listdir(os.path.join(train_dir,i)))\n",
        "\n",
        "for i in class_names:\n",
        "    valid_image_count[i] = len(os.listdir(os.path.join(valid_dir,i)))\n",
        "\n",
        "print(f\"TRAIN: {train_image_count}\")\n",
        "print(f\"VALIDATION: {valid_image_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0a7qhxnY9Kx"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "\n",
        "mean_nums = [0.485, 0.456, 0.406]\n",
        "std_nums = [0.229, 0.224, 0.225]\n",
        "\n",
        "def imshow(inp, size =(40,40), title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = mean_nums\n",
        "    std = std_nums\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.figure(figsize=size)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title, size=30)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "def visualize_model(model, num_images=9):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_handeled = 0\n",
        "    ax = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(testloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_handeled += 1\n",
        "                ax = plt.subplot(num_images, 2, images_handeled)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('Actual: {} Predicted: {}'.format(class_names[labels[j].item()],class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j], (16,4))\n",
        "\n",
        "                if images_handeled == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "1QEOsuJcZOkl",
        "outputId": "541f824c-5950-45dc-975e-878df52e926a"
      },
      "outputs": [],
      "source": [
        "# visualize_model(model,len(testloader))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm_l_naPc0Nv"
      },
      "outputs": [],
      "source": [
        "sonucKlasor = workspace_path + 'sonuclar/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mobileNetV3Sonuc = sonucKlasor + \"MobileNetV3/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mobileNetV3Sonuc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "Yo2cS5RZZQK3",
        "outputId": "1ed09462-f693-42f8-8de7-dc907fc067ec"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "# Önceden eğitilmiş modeli yükleyin\n",
        "MobileNetV3 = models.mobilenet_v3_large(pretrained=\"MobileNet_V3_Large_Weights.IMAGENET1K_V1\")\n",
        "num_ftrs = MobileNetV3.classifier[3].in_features\n",
        "MobileNetV3.classifier[3].in_features = nn.Linear(num_ftrs, 2)\n",
        "model = MobileNetV3\n",
        "# Tüm katmanları dondurun\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# Cihaz tipini tanımlayın\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Modeli cihaza taşıyın\n",
        "model.to(device)\n",
        "\n",
        "# Kayıp fonksiyonu ve optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Eğitim döngüsü\n",
        "epochs = 20\n",
        "best_accuracy = 0.0\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    accuracy = 0.0\n",
        "\n",
        "    # Eğitim aşaması\n",
        "    model.train()\n",
        "    for data, target in trainloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "    # Doğrulama aşaması\n",
        "    model.eval()\n",
        "    for data, target in validloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "\n",
        "        # Doğruluğu hesaplayın\n",
        "        prob = torch.exp(output)\n",
        "        top_p, top_class = prob.topk(1, dim=1)\n",
        "        equals = top_class == target.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "    # Sonuçları yazdırın\n",
        "    train_loss = train_loss/len(trainloader.dataset)\n",
        "    valid_loss = valid_loss/len(validloader.dataset)\n",
        "    accuracy = accuracy/len(validloader)\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tValidation Accuracy: {:.2f}%'.format(epoch+1, train_loss, valid_loss, accuracy*100))\n",
        "\n",
        "    torch.save(model.state_dict(), f\"C:/Users/celal/Documents/Github/goruntu-isleme-projesi/sonuclar/MobileNetV3/{epoch+1}epoch.pth\")\n",
        "    if accuracy >= best_accuracy:\n",
        "        print(\"Saving model with validation accuracy: {:.2f}%\".format(accuracy*100))\n",
        "        best_accuracy = accuracy\n",
        "        torch.save(model.state_dict(), f\"C:/Users/celal/Documents/Github/goruntu-isleme-projesi/sonuclar/MobileNetV3/best_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Z1vuoMSyZgx2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2 \tTraining Loss: 0.677820 \tValidation Loss: 0.908078 \tValidation Accuracy: 56.25%\n",
            "Epoch: 3 \tTraining Loss: 0.615068 \tValidation Loss: 0.815012 \tValidation Accuracy: 59.18%\n",
            "Epoch: 4 \tTraining Loss: 0.578109 \tValidation Loss: 0.668739 \tValidation Accuracy: 66.60%\n",
            "Saving model with validation accuracy: 66.60%\n",
            "Epoch: 5 \tTraining Loss: 0.542675 \tValidation Loss: 0.691266 \tValidation Accuracy: 64.45%\n",
            "Epoch: 6 \tTraining Loss: 0.514837 \tValidation Loss: 0.758758 \tValidation Accuracy: 65.62%\n",
            "Epoch: 7 \tTraining Loss: 0.492084 \tValidation Loss: 0.676669 \tValidation Accuracy: 64.06%\n",
            "Epoch: 8 \tTraining Loss: 0.451071 \tValidation Loss: 0.734401 \tValidation Accuracy: 67.19%\n",
            "Saving model with validation accuracy: 67.19%\n",
            "Epoch: 9 \tTraining Loss: 0.425306 \tValidation Loss: 1.293247 \tValidation Accuracy: 58.59%\n",
            "Epoch: 10 \tTraining Loss: 0.407713 \tValidation Loss: 0.730837 \tValidation Accuracy: 67.38%\n",
            "Saving model with validation accuracy: 67.38%\n",
            "Epoch: 11 \tTraining Loss: 0.362108 \tValidation Loss: 0.789928 \tValidation Accuracy: 66.99%\n",
            "Epoch: 12 \tTraining Loss: 0.305392 \tValidation Loss: 0.835892 \tValidation Accuracy: 68.55%\n",
            "Saving model with validation accuracy: 68.55%\n",
            "Epoch: 13 \tTraining Loss: 0.317818 \tValidation Loss: 0.745536 \tValidation Accuracy: 69.14%\n",
            "Saving model with validation accuracy: 69.14%\n",
            "Epoch: 14 \tTraining Loss: 0.333589 \tValidation Loss: 0.801399 \tValidation Accuracy: 68.55%\n",
            "Epoch: 15 \tTraining Loss: 0.291984 \tValidation Loss: 1.181604 \tValidation Accuracy: 63.48%\n",
            "Epoch: 16 \tTraining Loss: 0.295018 \tValidation Loss: 0.804044 \tValidation Accuracy: 68.16%\n",
            "Epoch: 17 \tTraining Loss: 0.246807 \tValidation Loss: 0.735648 \tValidation Accuracy: 71.09%\n",
            "Saving model with validation accuracy: 71.09%\n",
            "Epoch: 18 \tTraining Loss: 0.261469 \tValidation Loss: 1.018756 \tValidation Accuracy: 68.55%\n",
            "Epoch: 19 \tTraining Loss: 0.228561 \tValidation Loss: 0.814413 \tValidation Accuracy: 72.07%\n",
            "Saving model with validation accuracy: 72.07%\n",
            "Epoch: 20 \tTraining Loss: 0.214649 \tValidation Loss: 0.996554 \tValidation Accuracy: 68.16%\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "# Önceden eğitilmiş modeli yükleyin\n",
        "MobileNetV3small = models.mobilenet_v3_small(pretrained=\"MobileNet_V3_Small_Weights.IMAGENET1K_V1\")\n",
        "num_ftrs = MobileNetV3small.classifier[3].in_features\n",
        "MobileNetV3small.classifier[3].in_features = nn.Linear(num_ftrs, 2)\n",
        "model = MobileNetV3small\n",
        "# Tüm katmanları dondurun\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# Cihaz tipini tanımlayın\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Modeli cihaza taşıyın\n",
        "model.to(device)\n",
        "\n",
        "# Kayıp fonksiyonu ve optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Eğitim döngüsü\n",
        "epochs = 20\n",
        "best_accuracy = 0.0\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    accuracy = 0.0\n",
        "\n",
        "    # Eğitim aşaması\n",
        "    model.train()\n",
        "    for data, target in trainloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "    # Doğrulama aşaması\n",
        "    model.eval()\n",
        "    for data, target in validloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "\n",
        "        # Doğruluğu hesaplayın\n",
        "        prob = torch.exp(output)\n",
        "        top_p, top_class = prob.topk(1, dim=1)\n",
        "        equals = top_class == target.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "    # Sonuçları yazdırın\n",
        "    train_loss = train_loss/len(trainloader.dataset)\n",
        "    valid_loss = valid_loss/len(validloader.dataset)\n",
        "    accuracy = accuracy/len(validloader)\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tValidation Accuracy: {:.2f}%'.format(epoch+1, train_loss, valid_loss, accuracy*100))\n",
        "\n",
        "    torch.save(model.state_dict(), f\"C:/Users/celal/Documents/Github/goruntu-isleme-projesi/sonuclar/MobileNetV3small/{epoch+1}epoch.pth\")\n",
        "    if accuracy >= best_accuracy:\n",
        "        print(\"Saving model with validation accuracy: {:.2f}%\".format(accuracy*100))\n",
        "        best_accuracy = accuracy\n",
        "        torch.save(model.state_dict(), f\"C:/Users/celal/Documents/Github/goruntu-isleme-projesi/sonuclar/MobileNetV3small/best_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\celal\\.conda\\envs\\torchgpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.694039 \tValidation Loss: 0.684581 \tValidation Accuracy: 56.05%\n",
            "Saving model with validation accuracy: 56.05%\n",
            "Epoch: 2 \tTraining Loss: 0.692219 \tValidation Loss: 0.688950 \tValidation Accuracy: 55.47%\n",
            "Epoch: 3 \tTraining Loss: 0.686017 \tValidation Loss: 0.684681 \tValidation Accuracy: 54.30%\n",
            "Epoch: 4 \tTraining Loss: 0.681390 \tValidation Loss: 0.685954 \tValidation Accuracy: 55.27%\n",
            "Epoch: 5 \tTraining Loss: 0.680362 \tValidation Loss: 0.695654 \tValidation Accuracy: 49.61%\n",
            "Epoch: 6 \tTraining Loss: 0.678296 \tValidation Loss: 0.692454 \tValidation Accuracy: 53.32%\n",
            "Epoch: 7 \tTraining Loss: 0.681009 \tValidation Loss: 0.681822 \tValidation Accuracy: 55.66%\n",
            "Epoch: 8 \tTraining Loss: 0.672251 \tValidation Loss: 0.710692 \tValidation Accuracy: 50.20%\n",
            "Epoch: 9 \tTraining Loss: 0.667542 \tValidation Loss: 0.680944 \tValidation Accuracy: 56.25%\n",
            "Saving model with validation accuracy: 56.25%\n",
            "Epoch: 10 \tTraining Loss: 0.658907 \tValidation Loss: 0.671644 \tValidation Accuracy: 56.05%\n",
            "Epoch: 11 \tTraining Loss: 0.644701 \tValidation Loss: 0.650505 \tValidation Accuracy: 59.77%\n",
            "Saving model with validation accuracy: 59.77%\n",
            "Epoch: 12 \tTraining Loss: 0.626326 \tValidation Loss: 0.731642 \tValidation Accuracy: 55.08%\n",
            "Epoch: 13 \tTraining Loss: 0.626585 \tValidation Loss: 0.680475 \tValidation Accuracy: 57.81%\n",
            "Epoch: 14 \tTraining Loss: 0.610449 \tValidation Loss: 0.660932 \tValidation Accuracy: 60.35%\n",
            "Saving model with validation accuracy: 60.35%\n",
            "Epoch: 15 \tTraining Loss: 0.594190 \tValidation Loss: 0.650027 \tValidation Accuracy: 59.96%\n",
            "Epoch: 16 \tTraining Loss: 0.607450 \tValidation Loss: 0.677192 \tValidation Accuracy: 60.35%\n",
            "Saving model with validation accuracy: 60.35%\n",
            "Epoch: 17 \tTraining Loss: 0.587863 \tValidation Loss: 0.855332 \tValidation Accuracy: 58.20%\n",
            "Epoch: 18 \tTraining Loss: 0.579205 \tValidation Loss: 0.730268 \tValidation Accuracy: 58.40%\n",
            "Epoch: 19 \tTraining Loss: 0.575190 \tValidation Loss: 0.654361 \tValidation Accuracy: 60.94%\n",
            "Saving model with validation accuracy: 60.94%\n",
            "Epoch: 20 \tTraining Loss: 0.536222 \tValidation Loss: 0.759668 \tValidation Accuracy: 57.23%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "# Önceden eğitilmiş modeli yükleyin\n",
        "SqueezeNet = models.squeezenet1_1(pretrained=True)\n",
        "num_classes = 2  # Sınıf sayısına uygun olarak ayarlayın\n",
        "\n",
        "# SqueezeNet'in son tam bağlı katmanını değiştirin\n",
        "SqueezeNet.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
        "SqueezeNet.num_classes = num_classes\n",
        "\n",
        "model = SqueezeNet\n",
        "\n",
        "# Tüm katmanları dondurun\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# Cihaz tipini tanımlayın\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Modeli cihaza taşıyın\n",
        "model.to(device)\n",
        "\n",
        "# Kayıp fonksiyonu ve optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Eğitim döngüsü\n",
        "epochs = 20\n",
        "best_accuracy = 0.0\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    accuracy = 0.0\n",
        "\n",
        "    # Eğitim aşaması\n",
        "    model.train()\n",
        "    for data, target in trainloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "    # Doğrulama aşaması\n",
        "    model.eval()\n",
        "    for data, target in validloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "\n",
        "        # Doğruluğu hesaplayın\n",
        "        prob = torch.exp(output)\n",
        "        top_p, top_class = prob.topk(1, dim=1)\n",
        "        equals = top_class == target.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "    # Sonuçları yazdırın\n",
        "    train_loss = train_loss/len(trainloader.dataset)\n",
        "    valid_loss = valid_loss/len(validloader.dataset)\n",
        "    accuracy = accuracy/len(validloader)\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tValidation Accuracy: {:.2f}%'.format(epoch+1, train_loss, valid_loss, accuracy*100))\n",
        "\n",
        "    torch.save(model.state_dict(), f\"C:/Users/celal/Documents/Github/goruntu-isleme-projesi/sonuclar/SqueezeNet/{epoch+1}epoch.pth\")\n",
        "    if accuracy >= best_accuracy:\n",
        "        print(\"Saving model with validation accuracy: {:.2f}%\".format(accuracy*100))\n",
        "        best_accuracy = accuracy\n",
        "        torch.save(model.state_dict(), f\"C:/Users/celal/Documents/Github/goruntu-isleme-projesi/sonuclar/SqueezeNet/best_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\celal\\.conda\\envs\\torchgpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\" to C:\\Users\\celal/.cache\\torch\\hub\\checkpoints\\shufflenetv2_x1-5666bf0f80.pth\n",
            "100%|██████████| 8.79M/8.79M [00:01<00:00, 5.09MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.688730 \tValidation Loss: 0.686953 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 2 \tTraining Loss: 0.687278 \tValidation Loss: 0.686996 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 3 \tTraining Loss: 0.687020 \tValidation Loss: 0.686649 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 4 \tTraining Loss: 0.687134 \tValidation Loss: 0.686375 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 5 \tTraining Loss: 0.686577 \tValidation Loss: 0.686128 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 6 \tTraining Loss: 0.686408 \tValidation Loss: 0.686128 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 7 \tTraining Loss: 0.686384 \tValidation Loss: 0.685710 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 8 \tTraining Loss: 0.685294 \tValidation Loss: 0.686032 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 9 \tTraining Loss: 0.686088 \tValidation Loss: 0.685143 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 10 \tTraining Loss: 0.685377 \tValidation Loss: 0.684973 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 11 \tTraining Loss: 0.684724 \tValidation Loss: 0.684516 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 12 \tTraining Loss: 0.684338 \tValidation Loss: 0.683955 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 13 \tTraining Loss: 0.684081 \tValidation Loss: 0.683478 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 14 \tTraining Loss: 0.684207 \tValidation Loss: 0.683045 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 15 \tTraining Loss: 0.683158 \tValidation Loss: 0.682229 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 16 \tTraining Loss: 0.682527 \tValidation Loss: 0.680982 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n",
            "Epoch: 17 \tTraining Loss: 0.681121 \tValidation Loss: 0.680147 \tValidation Accuracy: 55.47%\n",
            "Saving model with validation accuracy: 55.47%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "# Önceden eğitilmiş modeli yükleyin\n",
        "ShuffleNet = models.shufflenet_v2_x1_0(pretrained=True)\n",
        "num_classes = 2  # Sınıf sayısına uygun olarak ayarlayın\n",
        "\n",
        "# ShuffleNet'in son tam bağlı katmanını değiştirin\n",
        "ShuffleNet.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "model = ShuffleNet\n",
        "\n",
        "# Tüm katmanları dondurun\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# Cihaz tipini tanımlayın\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Modeli cihaza taşıyın\n",
        "model.to(device)\n",
        "\n",
        "# Kayıp fonksiyonu ve optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Eğitim döngüsü\n",
        "epochs = 20\n",
        "best_accuracy = 0.0\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    accuracy = 0.0\n",
        "\n",
        "    # Eğitim aşaması\n",
        "    model.train()\n",
        "    for data, target in trainloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "    # Doğrulama aşaması\n",
        "    model.eval()\n",
        "    for data, target in validloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "\n",
        "        # Doğruluğu hesaplayın\n",
        "        prob = torch.exp(output)\n",
        "        top_p, top_class = prob.topk(1, dim=1)\n",
        "        equals = top_class == target.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "    # Sonuçları yazdırın\n",
        "    train_loss = train_loss/len(trainloader.dataset)\n",
        "    valid_loss = valid_loss/len(validloader.dataset)\n",
        "    accuracy = accuracy/len(validloader)\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tValidation Accuracy: {:.2f}%'.format(epoch+1, train_loss, valid_loss, accuracy*100))\n",
        "\n",
        "    torch.save(model.state_dict(), f\"C:/Users/celal/Documents/Github/goruntu-isleme-projesi/sonuclar/ShuffleNet/{epoch+1}epoch.pth\")\n",
        "    if accuracy >= best_accuracy:\n",
        "        print(\"Saving model with validation accuracy: {:.2f}%\".format(accuracy*100))\n",
        "        best_accuracy = accuracy\n",
        "        torch.save(model.state_dict(), f\"C:/Users/celal/Documents/Github/goruntu-isleme-projesi/sonuclar/ShuffleNet/best_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
